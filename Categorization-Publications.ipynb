{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Biblotecas de Apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ricardo/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449904 sha256=a3b662b5b6914ebaf90c2d3783e0029254a199c78d4897c0063f98694653a382\n",
      "  Stored in directory: /home/ricardo/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip --user\n",
    "# !pip install tensorflow==2.0.0-rc0 --user\n",
    "# !pip install keras --user\n",
    "# !pip install --user -U nltk\n",
    "\n",
    "\n",
    "# !conda create --name PythonGPU\n",
    "# !activate PythonCPU\n",
    "# !conda install -c anaconda keras\n",
    "# !conda install -c anaconda keras-gpu\n",
    "\n",
    "# !conda install -c theano\n",
    "# !conda install -c conda-forge keras tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Importação das Biblotecas Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/test.csv\n",
      "input/train.csv\n",
      "input/sample_submission.csv\n",
      "input/train.csv.gz\n",
      "input/test.pkl\n",
      "input/train.pkl\n"
     ]
    }
   ],
   "source": [
    "# Carrega as bibliotecas de ambiente\n",
    "\n",
    "import os\n",
    "import io\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import collections\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for dirname, _, filenames in os.walk('input/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Importação das Biblotecas Específicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ricardo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(700, 10, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega as bibliotecas de ciências e gráficos\n",
    "\n",
    "import pickle\n",
    "\n",
    "import theano\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from numba import vectorize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "\n",
    "gc.get_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Importação de Dados de Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ricardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação das stopwords do pacote nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Definição das Constantes de Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para os arquivos de dados\n",
    "PATH = \"input/\"\n",
    "\n",
    "# Regex\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "LESS_THAN_WORD = re.compile(r'\\b\\w{1,2}\\b')\n",
    "REMOVE_NUMBERS = re.compile(' \\d+')\n",
    "\n",
    "# Stopwords\n",
    "STOPWORDS_0 = set(stopwords.words('english'))\n",
    "STOPWORDS_1 = set(stopwords.words('portuguese'))\n",
    "STOPWORDS_2 = set(stopwords.words('spanish'))\n",
    "\n",
    "\n",
    "# Número máximo de palavras usadas mais frequentes\n",
    "MAX_NB_WORDS = 50000\n",
    "# Numero máximo de palavras para saída\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# Fixador.\n",
    "EMBEDDING_DIM = 100\n",
    "# Variável randomica\n",
    "RANDOM_STATE = 2011\n",
    "\n",
    "# Número de épocas\n",
    "EPOCHS = 15\n",
    "# Tamanho do bloco\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funções de Apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria ou lê os dados pickle\n",
    "def file_pickle(file):\n",
    "    fpkl = PATH + file + \".pkl\"\n",
    "    fcsv = PATH + file + \".csv\"\n",
    "  \n",
    "    if os.path.isfile(fpkl):\n",
    "        df = pd.read_pickle(fpkl)\n",
    "    else:        \n",
    "        df = pd.read_csv(fcsv, header=0, sep=',', quotechar='\"', error_bad_lines=False, skipinitialspace=True)\n",
    "        df.to_pickle(fpkl)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Atualiza o arquivo pickle com novas informações\n",
    "def update_pickle(file, df):\n",
    "    fpkl = PATH + file + \".pkl\"\n",
    "    df.to_pickle(fpkl)\n",
    "    \n",
    "# Imprime os dados relativos ao indice passado\n",
    "def print_plot(index):\n",
    "    example = dftrain[dftrain.index == index][['title', 'category']].values[0]\n",
    "    \n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Category:', example[1])\n",
    "        \n",
    "# Limpeza dos dados: lower case; espaços do texto; caracteres especiais e simbolos; stop words e digitos\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = LESS_THAN_WORD.sub('', text) # replace LESS_THAN_WORD symbols by space in text. substitute the matched string in LESS_THAN_WORD with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = REMOVE_NUMBERS.sub('', text) # remove numbers which are in REMOVE_NUMBERS from text. substitute the matched string in REMOVE_NUMBERS with nothing. \n",
    "    text = text.replace('  ', ' ')\n",
    "\n",
    "    #    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS_0) # remove stopwors english from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS_1) # remove stopwors portugues from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS_2) # remove stopwors spanish from text\n",
    "    text = text.replace('\\d+', '')\n",
    "        \n",
    "    return text\n",
    "\n",
    "# Tokenização de textos\n",
    "def token_text(text):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters=string.punctuation, lower=True)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return sequences\n",
    "\n",
    "# Conversão de texto para variável categórica\n",
    "def dummie_text(text):\n",
    "    dummies = pd.get_dummies(text).values\n",
    "    \n",
    "    return dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Coleta de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Carga dos Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ELECTRIC_PRESSURE_WASHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Placa De Sonido - Behringer Umc22</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SOUND_CARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maquina De Lavar Electrolux 12 Kilos</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WASHING_MACHINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Par Disco De Freio Diant Vent Gol 8v 08/ Frema...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>VEHICLE_BRAKE_DISCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flashes Led Pestañas Luminoso Falso Pestañas P...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FALSE_EYELASHES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_quality  \\\n",
       "0  Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...    unreliable   \n",
       "1                  Placa De Sonido - Behringer Umc22    unreliable   \n",
       "2               Maquina De Lavar Electrolux 12 Kilos    unreliable   \n",
       "3  Par Disco De Freio Diant Vent Gol 8v 08/ Frema...    unreliable   \n",
       "4  Flashes Led Pestañas Luminoso Falso Pestañas P...    unreliable   \n",
       "\n",
       "     language                   category  \n",
       "0     spanish  ELECTRIC_PRESSURE_WASHERS  \n",
       "1     spanish                SOUND_CARDS  \n",
       "2  portuguese           WASHING_MACHINES  \n",
       "3  portuguese        VEHICLE_BRAKE_DISCS  \n",
       "4     spanish            FALSE_EYELASHES  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urltrain = \"https://meli-data-challenge.s3.amazonaws.com/train.csv.gz\"\n",
    "# ctrain = requests.get(urltrain).content\n",
    "# ftrain = pd.read_csv(io.StringIO(ctrain.decode('utf-8')), compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, skipinitialspace=True)\n",
    "# dftrain = pd.read_csv(\"input/train.csv.gz\", compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, skipinitialspace=True)\n",
    "\n",
    "dftrain = file_pickle(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Carga dos Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kit Maternidade Bolsa-mala Baby/bebe Vinho Men...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trocador De Fraldas Fisher Price Feminino Rosa...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Motor Ventoinha - Fiat Idea / Palio 1.8 - A 04...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Amortecedor Mola Batente D Dir New Civic 14 - ...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cadeirinha De Carro Bebê Princesa Princess 9 A...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title    language\n",
       "0   0  Kit Maternidade Bolsa-mala Baby/bebe Vinho Men...  portuguese\n",
       "1   1  Trocador De Fraldas Fisher Price Feminino Rosa...  portuguese\n",
       "2   2  Motor Ventoinha - Fiat Idea / Palio 1.8 - A 04...  portuguese\n",
       "3   3  Amortecedor Mola Batente D Dir New Civic 14 - ...  portuguese\n",
       "4   4  Cadeirinha De Carro Bebê Princesa Princess 9 A...  portuguese"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urltest = \"https://meli-data-challenge.s3.amazonaws.com/test.csv\"\n",
    "# ctest = requests.get(urltest).content\n",
    "# ftest = pd.read_csv(io.StringIO(ctest.decode('utf-8')), header=0, sep=',', quotechar='\"', error_bad_lines=False, skipinitialspace=True)\n",
    "# dftest = pd.read_csv(\"input/test.csv\", header=0, sep=',', quotechar='\"', error_bad_lines=False, skipinitialspace=True)\n",
    "\n",
    "dftest = file_pickle(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Limpeza da Memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "gc.get_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processamento/Tratamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Análise dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset  (20000000, 4)\n",
      "Index(['title', 'label_quality', 'language', 'category'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ELECTRIC_PRESSURE_WASHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Placa De Sonido - Behringer Umc22</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SOUND_CARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maquina De Lavar Electrolux 12 Kilos</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WASHING_MACHINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Par Disco De Freio Diant Vent Gol 8v 08/ Frema...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>VEHICLE_BRAKE_DISCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flashes Led Pestañas Luminoso Falso Pestañas P...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FALSE_EYELASHES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_quality  \\\n",
       "0  Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...    unreliable   \n",
       "1                  Placa De Sonido - Behringer Umc22    unreliable   \n",
       "2               Maquina De Lavar Electrolux 12 Kilos    unreliable   \n",
       "3  Par Disco De Freio Diant Vent Gol 8v 08/ Frema...    unreliable   \n",
       "4  Flashes Led Pestañas Luminoso Falso Pestañas P...    unreliable   \n",
       "\n",
       "     language                   category  \n",
       "0     spanish  ELECTRIC_PRESSURE_WASHERS  \n",
       "1     spanish                SOUND_CARDS  \n",
       "2  portuguese           WASHING_MACHINES  \n",
       "3  portuguese        VEHICLE_BRAKE_DISCS  \n",
       "4     spanish            FALSE_EYELASHES  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica a estrutura básica dos dados de treino\n",
    "\n",
    "print('Shape of dataset ',dftrain.shape)\n",
    "print(dftrain.columns)\n",
    "\n",
    "dftrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000000 entries, 0 to 19999999\n",
      "Data columns (total 4 columns):\n",
      "title            object\n",
      "label_quality    object\n",
      "language         object\n",
      "category         object\n",
      "dtypes: object(4)\n",
      "memory usage: 610.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verificação das caracteristicas de cada coluna do arquivo\n",
    "\n",
    "dftrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nos dados de treino não existem dados nulos.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se exitem dados nulos no geral\n",
    "\n",
    "if dftrain.isnull().values.any():\n",
    "    dftrain[dftrain.isnull().any(axis=1)] \n",
    "else:\n",
    "    print(\"Nos dados de treino não existem dados nulos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dados ausentes\n",
    "\n",
    "dftrain = dftrain.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinindo o indice do dataframe\n",
    "\n",
    "dftrain = dftrain.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PANTS                                   35973\n",
       "COFFEE_MAKERS                           35104\n",
       "BABY_CAR_SEATS                          34163\n",
       "MUSICAL_KEYBOARDS                       33222\n",
       "MATTRESSES                              32967\n",
       "PUREBRED_DOGS                           32928\n",
       "RANGES                                  32645\n",
       "REFRIGERATORS                           32635\n",
       "MOTORCYCLE_JACKETS                      32615\n",
       "HAIR_CLIPPERS                           32372\n",
       "SHORTS                                  31685\n",
       "SUITCASES                               31580\n",
       "MEMORY_CARDS                            31564\n",
       "WINES                                   31399\n",
       "ROLLER_SKATES                           31371\n",
       "BABY_STROLLERS                          31353\n",
       "SEWING_MACHINES                         31129\n",
       "ELECTRIC_DRILLS                         30820\n",
       "KITCHEN_SINKS                           30635\n",
       "WALL_CLOCKS                             30600\n",
       "FLASHLIGHTS                             29960\n",
       "CV_JOINTS                               29676\n",
       "SWEATERS_AND_CARDIGANS                  29608\n",
       "BOOKS                                   29464\n",
       "PORTABLE_GENERATORS                     29384\n",
       "BOOKCASES                               29372\n",
       "AIR_COMPRESSORS                         29259\n",
       "TV_AND_MONITOR_MOUNTS                   29214\n",
       "CHOCOLATES                              29038\n",
       "RACQUETS                                28980\n",
       "                                        ...  \n",
       "STORE_SHOPPING_CARTS                      593\n",
       "ANGLE_CLAMPS                              577\n",
       "INDUSTRIAL_BLENDERS                       569\n",
       "INFLATABLE_SLIDES                         569\n",
       "FOOD_AND_DRINK_COLORINGS                  562\n",
       "WAITER_CALLING_SYSTEMS                    544\n",
       "FOOT_BATH_MASSAGERS                       519\n",
       "3D_PENS                                   507\n",
       "HARD_DRIVE_AND_SSD_ADAPTER_CABLES         507\n",
       "CANOES                                    486\n",
       "TILE_AND_CLADDING_ADHESIVE_MIXTURES       484\n",
       "CHECKOUT_COUNTERS                         431\n",
       "SAPO_GAMES                                426\n",
       "CPR_TRAINING_MANIKINS                     416\n",
       "WAKEBOARD_BOOTS                           387\n",
       "MARTIAL_ARTS_CHEST_GUARDS                 327\n",
       "LENTILS                                   313\n",
       "PLATE_COMPACTORS                          305\n",
       "BOXING_SPEED_BAGS                         288\n",
       "MANUAL_TROLLEYS                           277\n",
       "SCALE_RULERS                              266\n",
       "QUEUE_STANCHIONS                          253\n",
       "STADIOMETERS                              229\n",
       "HONEY_EXTRACTORS                          216\n",
       "FORCE_GAUGES                              213\n",
       "CONSTRUCTION_LIME_BAGS                    206\n",
       "COLD_FOOD_AND_DRINK_VENDING_MACHINES      162\n",
       "PAINTBALL_SMOKE_GRENADES                  154\n",
       "COMMERCIAL_POPCORN_MACHINES               141\n",
       "HAMBURGER_FORMERS                         109\n",
       "Name: category, Length: 1588, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os tipos de categorias\n",
    "\n",
    "dftrain.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Análise dos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset  (246955, 3)\n",
      "Index(['id', 'title', 'language'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kit Maternidade Bolsa-mala Baby/bebe Vinho Men...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trocador De Fraldas Fisher Price Feminino Rosa...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Motor Ventoinha - Fiat Idea / Palio 1.8 - A 04...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Amortecedor Mola Batente D Dir New Civic 14 - ...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cadeirinha De Carro Bebê Princesa Princess 9 A...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title    language\n",
       "0   0  Kit Maternidade Bolsa-mala Baby/bebe Vinho Men...  portuguese\n",
       "1   1  Trocador De Fraldas Fisher Price Feminino Rosa...  portuguese\n",
       "2   2  Motor Ventoinha - Fiat Idea / Palio 1.8 - A 04...  portuguese\n",
       "3   3  Amortecedor Mola Batente D Dir New Civic 14 - ...  portuguese\n",
       "4   4  Cadeirinha De Carro Bebê Princesa Princess 9 A...  portuguese"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica a estrutura básica dos dados de teste\n",
    "\n",
    "print('Shape of dataset ',dftest.shape)\n",
    "print(dftest.columns)\n",
    "\n",
    "dftest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246955 entries, 0 to 246954\n",
      "Data columns (total 3 columns):\n",
      "id          246955 non-null int64\n",
      "title       246955 non-null object\n",
      "language    246955 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verificação das caracteristicas de cada coluna do arquivo\n",
    "\n",
    "dftest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nos dados de teste não existem dados nulos.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se exitem dados nulos no geral\n",
    "\n",
    "if dftest.isnull().values.any():\n",
    "    dftest[dftest.isnull().any(axis=1)] \n",
    "else:\n",
    "   print(\"Nos dados de teste não existem dados nulos.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dados ausentes\n",
    "\n",
    "dftest = dftest.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinindo o indice do dataframe\n",
    "\n",
    "dftest = dftest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 - Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kit maternidade bolsamala baby bebe vinho meni...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trocador fraldas fisher price feminino rosa po...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>motor ventoinha fiat idea palio 0417</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>amortecedor mola batente dir new civic 7051</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cadeirinha carro beb princesa princess kgs</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title    language\n",
       "0   0  kit maternidade bolsamala baby bebe vinho meni...  portuguese\n",
       "1   1  trocador fraldas fisher price feminino rosa po...  portuguese\n",
       "2   2               motor ventoinha fiat idea palio 0417  portuguese\n",
       "3   3        amortecedor mola batente dir new civic 7051  portuguese\n",
       "4   4         cadeirinha carro beb princesa princess kgs  portuguese"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpeza\n",
    "dftrain['titles'] = dftrain['title'].apply(clean_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"train\", dftrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 - Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "dftest['titles'] = dftest['title'].apply(clean_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"test\", dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 - Convertendo as variáveis caracter  em categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1 - Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão - Lingua\n",
    "dftrain['language_'] = dftrain['language'].apply(dummie_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"train\", dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão - Categoria\n",
    "dftrain['category_'] = dftrain['category'].apply(dummie_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"train\", dftrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 - Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão - Lingua\n",
    "dftest['language_'] = dftest['language'].apply(dummie_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"test\", dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 - Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1 - Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizando os testos do Title - Treino\n",
    "dftrain['title_'] = dftrain['titles'].apply(token_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"train\", dftrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 - Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizando os testos do Title - Teste\n",
    "\n",
    "dftest['title_'] = dftest['titles'].apply(token_text)\n",
    "\n",
    "# Atualização do dump\n",
    "update_pickle(\"test\", dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise e Exploração dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de como os textos ficaram após a limpeza:\n",
    "\n",
    "print_plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Placa De Sonido - Behringer Umc22</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maquina De Lavar Electrolux 12 Kilos</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Par Disco De Freio Diant Vent Gol 8v 08/ Frema...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flashes Led Pestañas Luminoso Falso Pestañas P...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    language\n",
       "0  Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...     spanish\n",
       "1                  Placa De Sonido - Behringer Umc22     spanish\n",
       "2               Maquina De Lavar Electrolux 12 Kilos  portuguese\n",
       "3  Par Disco De Freio Diant Vent Gol 8v 08/ Frema...  portuguese\n",
       "4  Flashes Led Pestañas Luminoso Falso Pestañas P...     spanish"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain[[\"title\", \"language\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preparração dos dados para aplicação dos Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as variáveis para execução dos modelos\n",
    "\n",
    "X_train = dftrain[[\"title_\", \"language_\"]]\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "Y_train = dftrain[\"category_\"]\n",
    "print('Shape of label tensor:', Y.shape)\n",
    "\n",
    "X_test = dftest[[\"title_\", \"language_\"]]\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verificação do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)\n",
    "print(neigh.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1 - Simulação do modelo com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = dftest[\"title\"].apply(token_text)\n",
    "pred = model.predict(padded)\n",
    "\n",
    "labels = dftrain['category'].value_counts()\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.2 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(len(macronum), activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"Simplified convolutional neural network\")\n",
    "model.summary()\n",
    "cp = ModelCheckpoint('model_cnn.hdf5', monitor='val_acc',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=EPOCHS, batch_size=BATCH_SIZE,callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves :CNN',fontsize=16)\n",
    "fig1.savefig('loss_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=plt.figure()\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves : CNN',fontsize=16)\n",
    "fig2.savefig('accuracy_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 - Simulação do modelo com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = dftest[\"title\"].apply(token_text)\n",
    "pred = model.predict(padded)\n",
    "\n",
    "labels = dftrain['category'].value_counts()\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.3 - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1 - Simulação do modelo com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = dftest[\"title\"].apply(token_text)\n",
    "pred = model.predict(padded)\n",
    "\n",
    "labels = dftrain['category'].value_counts()\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.4 - HAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.1 - Simulação do modelo com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = dftest[\"title\"].apply(token_text)\n",
    "pred = model.predict(padded)\n",
    "\n",
    "labels = dftrain['category'].value_counts()\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
